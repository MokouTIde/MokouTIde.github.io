## A$`^2`$RMS

Two alternative strategies are raised to improve the standard ARMS algorithm. We denote these two variants as A$`^2`$RMS and IA$`^2`$RMS where the A$`^2`$ emphasizes that we incorporate an additional adaptive step to improve the proposal density w.r.t. the standard ARMS.

**Algorithm Doubly adaptive rejection Metropolis sampling (A$`^2`$RMS).**

$(1)$ Initialization: Set $`t=0`$ (chain’s iteration) and $`m=0`$ (algorithm’s iteration). Choose an initial state $`(\theta^{(0)})`$, an initial number of support points $`(K_0)`$, an initial support set $`S(0)=\left\{\theta_1^{(0)},\cdots,\theta_{K_0}^{(0)}\right\}`$, the number of additional adaptive step $T_l$, the total number of iterations $`(T)`$ and the burn-in period $`(T_b)`$.

$(2)$ WHILE $`t\leq T`$:

(a) Build a proposal function,$q_m(\theta)$, given a set of support points $`S^{(m)}=\left\{\theta_1^{(m)},\theta_2^{(m)},\cdots,\theta_{K_0}^{(m)}\right\}`$, use some simple non-parametric approach.

(b) Draw $`\theta'\sim \bar{q}_m(\theta)`$ and $`u\sim U([0,1))`$.

(c) If $`u> \frac{\pi(\theta')}{q_m(\theta')}`$, then reject $\theta'$, update $`S^{m+1}=S^{m} \cup \left\{ \theta' \right\},K_{m+1}=K_m+1`$, and set $`m=m+1`$. Go back to step 2(a).

(d) Otherwise(i.e., if $`u \leq \pi(\theta')/q_m(\theta')`$), draw $`u'\sim U([0,1))`$ and compute the acceptance probability:

$$\alpha_t\equiv \alpha(\theta',\theta^{(t-1)})=min[1,\frac{\pi(\theta')min[\pi(\theta^{(t-1)}),q_m(\theta^{(t-1)})]}{\pi(\theta^{(t-1)})min[\pi(\theta'),q_m(\theta')]}]$$

(e)If $`m\leq T_l`$, draw $`u''\sim U([0,1])`$, if $`u''>q_m(\theta')/\pi(\theta')`$, set $`S^{(m+1)}=S^{(m)}\cup \mathcal{\theta'}`$ and $`K_{m+1}=K_m+1`$ and sort $`S_{t+1}`$ in ascending order. Otherwise, set $`S^{(m+1)}=S^{(m)}`$ and $`K_{m+1}=K_m`$.

$(3)$ Approximate the integral: 
```math
\hat{I}_{(T-T_b)}=\frac{1}{T-T_b} \sum_{t=T_b+1}^{T} g(\theta^{(t)})
```

## IA$`^2`$RMS

**Algorithm Independent doubly adaptive rejection Metropolis sampling (IA$`^2`$RMS).**

$(1)$ Initialization: Set $`t=0`$ (chain’s iteration) and $`m=0`$ (algorithm’s iteration). Choose an initial state $`(\theta^{(0)})`$, an initial number of support points $`(K_0)`$, an initial support set $`S(0)=\left\{\theta_1^{(0)},\cdots,\theta_{K_0}^{(0)}\right\}`$, the total number of iterations $`(T)`$ and the burn-in period $`(T_b)`$.

$(2)$ WHILE $`t\leq T`$:

(a) Build a proposal function, $`q_m(\theta)`$, given a set of support points $`S^{(m)}=\left\{\theta_1^{(m)},\theta_2^{(m)},\cdots,\theta_{K_0}^{(m)}\right\}`$, use some simple non-parametric approach.

(b) Draw $`\theta'\sim \bar{q}_m(\theta)`$ and $`u\sim U([0,1))`$.

(c) If $`u> \frac{\pi(\theta')}{q_m(\theta')}`$, then reject $`\theta'`$, update $`S^{m+1}=S^{m} \cup \left\{ \theta' \right\},K_{m+1}=K_m+1`$, and set $`m=m+1`$. Go back to step 2(a).

(d) Otherwise(i.e., if $`u \leq \pi(\theta')/q_m(\theta')`$), draw $u'\sim U([0,1))$ and compute the acceptance probability:

$$\alpha_t\equiv \alpha(\theta',\theta^{(t-1)})=min[1,\frac{\pi(\theta')min[\pi(\theta^{(t-1)}),q_m(\theta^{(t-1)})]}{\pi(\theta^{(t-1)})min[\pi(\theta'),q_m(\theta')]}]$$

(e) If $`u'\leq \alpha_t`$, accept $`\theta'`$ and set $`\theta^{(t)}=\theta'`$. Otherwise (i.e., if $`u'<\alpha_t`$), reject $`\theta'`$ and set $`\theta^{(t)}=\theta^{(t-1)}`$ and $`\vartheta=\theta'`$.

(f) Draw $`u''\sim U([0,1))`$. If $`u''>q_m(\vartheta)/\pi(\vartheta)`$, set $`S^{(m+1)}=S^{(m)}\cup \left\{\vartheta\right\}`$ and $`K_{m+1}=K_m+1`$. Otherwise, (i.e., if $`u''\leq q_m(\vartheta)/\pi(\vartheta)`$), set $`S^{(m+1)}=S^{(m)}$ and $K_{m+1}=K_m+1`$.

(g) Set $`m=m+1,t=t+1`$ and return to step 2(a).

$(3)$ Approximate the integral:
```math
\hat{I}_{(T-T_b)}=\frac{1}{T-T_b} \sum_{t=T_b+1}^{T} g(\theta^{(t)})
```
